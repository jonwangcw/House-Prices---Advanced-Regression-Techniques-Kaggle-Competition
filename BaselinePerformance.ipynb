{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f774835a-78ec-43bf-946e-f18a9637d237",
   "metadata": {},
   "source": [
    "# Kaggle House Price Competition - Baseline Performance Testing\n",
    "\n",
    "This notebook tests the baseline performance of various models on the data with no feature engineering. The only exception is using LabelEncoder from sklearn to convert categorical data to numerical values that can be read by the model.\n",
    "\n",
    "## Models tried \n",
    "\n",
    "- Support Vector Regression\n",
    "- Random Forest\n",
    "- AdaBoost\n",
    "- XGBoost\n",
    "- Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99fb7d0f-e75e-43c9-9e2c-fdb822b95d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOAD DATA\n",
      "Number of features: 81\n",
      "Number of data points: 1460\n",
      "TRAIN SVR\n",
      "TRAIN RANDOM FOREST\n",
      "TRAIN ADABOOST\n",
      "TRAIN XGBOOST\n",
      "TRAIN NEURAL NET (128/64 NEURONS)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jwng0\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS (DELETED)\n",
      "-----------------\n",
      "Support Vector Regression MSE: 7.86e+09\n",
      "Random Forest MSE: 8.32e+08\n",
      "AdaBoost MSE: 1.35e+09\n",
      "XGBoost MSE: 7.64e+08\n",
      "Neural Network MSE: 5.88e+09\n",
      "===========================================\n",
      "RESULTS (IMPUTED)\n",
      "-----------------\n",
      "Support Vector Regression MSE: 7.73e+09\n",
      "Random Forest MSE: 8.59e+08\n",
      "AdaBoost MSE: 1.34e+09\n",
      "XGBoost MSE: 1.08e+09\n",
      "Neural Network MSE: 7.69e+09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jwng0\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import random\n",
    "\n",
    "# Set random seed for reproducibility and stability of comparisons\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Load data\n",
    "print('LOAD DATA')\n",
    "training_data = pd.read_csv('train.csv') \n",
    "\n",
    "# Print basics\n",
    "n_features = len(training_data.columns)\n",
    "print(f'Number of features: {n_features}')\n",
    "n_entries = training_data.shape[0]\n",
    "print(f'Number of data points: {n_entries}')\n",
    "\n",
    "# Map features with string datatype entries to integers\n",
    "# Identify columns with object data type\n",
    "object_columns = training_data.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Map object entries to integers for each object column\n",
    "for col in object_columns:\n",
    "    training_data[col], _ = pd.factorize(training_data[col])\n",
    "\n",
    "# Training data with missing features deleted\n",
    "training_data_deleted = training_data.copy()\n",
    "training_data_deleted = training_data_deleted.drop(columns=['LotFrontage', 'MasVnrArea', 'GarageYrBlt'])\n",
    "\n",
    "# Fill missing training data with imputed values\n",
    "lf = training_data['LotFrontage'].dropna()\n",
    "mva = training_data['MasVnrArea'].dropna()\n",
    "gyb = training_data['GarageYrBlt'].dropna()\n",
    "\n",
    "lf_mean = lf[lf < 250].mean() # Drop outlier around 300\n",
    "mva_med = mva.median()\n",
    "gyb_mean = gyb.mean()\n",
    "\n",
    "training_data_filled = training_data.copy()\n",
    "training_data_filled['LotFrontage'] = training_data_filled['LotFrontage'].fillna(lf_mean)\n",
    "training_data_filled['MasVnrArea'] = training_data_filled['MasVnrArea'].fillna(mva_med)\n",
    "training_data_filled['GarageYrBlt'] = training_data_filled['GarageYrBlt'].fillna(gyb_mean)\n",
    "\n",
    "# Split data into features and target\n",
    "X_deleted = training_data_deleted.drop(columns='SalePrice')\n",
    "y_deleted = training_data_deleted['SalePrice']\n",
    "X_imputed = training_data_filled.drop(columns='SalePrice')\n",
    "y_imputed = training_data_filled['SalePrice']\n",
    "\n",
    "# Standardize data\n",
    "scaler = StandardScaler()\n",
    "X_deleted_scaled = scaler.fit_transform(X_deleted)\n",
    "X_imputed_scaled = scaler.fit_transform(X_imputed)\n",
    "\n",
    "# Split data into training and test set\n",
    "Xd_train, Xd_test, yd_train, yd_test = train_test_split(X_deleted_scaled, y_deleted, test_size=0.2)\n",
    "Xi_train, Xi_test, yi_train, yi_test = train_test_split(X_imputed_scaled, y_imputed, test_size=0.2)\n",
    "\n",
    "# Initialize models\n",
    "svr_model = SVR(kernel='rbf')  # Support Vector Regression\n",
    "rf_model = RandomForestRegressor()  # Random Forest\n",
    "ada_model = AdaBoostRegressor()  # AdaBoost\n",
    "xgb_model = XGBRegressor()  # XGBoost\n",
    "\n",
    "# Neural Network (using TensorFlow/Keras)\n",
    "nn_model = MLPRegressor(hidden_layer_sizes=(128, 64), activation='relu', solver='adam')\n",
    "\n",
    "############################\n",
    "# DELETED FEATURES SECTION #\n",
    "############################\n",
    "\n",
    "# Train models on data w/ deletions\n",
    "print('TRAIN SVR')\n",
    "svr_model.fit(Xd_train, yd_train)\n",
    "print('TRAIN RANDOM FOREST')\n",
    "rf_model.fit(Xd_train, yd_train)\n",
    "print('TRAIN ADABOOST')\n",
    "ada_model.fit(Xd_train, yd_train)\n",
    "print('TRAIN XGBOOST')\n",
    "xgb_model.fit(Xd_train, yd_train)\n",
    "print('TRAIN NEURAL NET (128/64 NEURONS)')\n",
    "nn_model.fit(Xd_train, yd_train)\n",
    "\n",
    "# Generate predictions (deleted)\n",
    "svr_pred = svr_model.predict(Xd_test)\n",
    "rf_pred = rf_model.predict(Xd_test)\n",
    "ada_pred = ada_model.predict(Xd_test)\n",
    "xgb_pred = xgb_model.predict(Xd_test)\n",
    "nn_pred = nn_model.predict(Xd_test)\n",
    "\n",
    "# Evaluation: Mean Squared Error (MSE) on test set (deleted)\n",
    "svr_mse_d = mean_squared_error(yd_test, svr_pred)\n",
    "rf_mse_d = mean_squared_error(yd_test, rf_pred)\n",
    "ada_mse_d = mean_squared_error(yd_test, ada_pred)\n",
    "xgb_mse_d = mean_squared_error(yd_test, xgb_pred)\n",
    "nn_mse_d = mean_squared_error(yd_test, nn_pred)\n",
    "\n",
    "# Print results (deleted)\n",
    "print('RESULTS (DELETED)')\n",
    "print('-----------------')\n",
    "print(f\"Support Vector Regression MSE: {svr_mse_d:.2e}\")\n",
    "print(f\"Random Forest MSE: {rf_mse_d:.2e}\")\n",
    "print(f\"AdaBoost MSE: {ada_mse_d:.2e}\")\n",
    "print(f\"XGBoost MSE: {xgb_mse_d:.2e}\")\n",
    "print(f\"Neural Network MSE: {nn_mse_d:.2e}\")\n",
    "\n",
    "print('===========================================')\n",
    "\n",
    "############################\n",
    "# IMPUTED FEATURES SECTION #\n",
    "############################\n",
    "\n",
    "# Train models on data w/ imputations\n",
    "svr_model.fit(Xi_train, yi_train)\n",
    "rf_model.fit(Xi_train, yi_train)\n",
    "ada_model.fit(Xi_train, yi_train)\n",
    "xgb_model.fit(Xi_train, yi_train)\n",
    "nn_model.fit(Xi_train, yi_train)\n",
    "\n",
    "# Generate predictions (imputed)\n",
    "svr_pred = svr_model.predict(Xi_test)\n",
    "rf_pred = rf_model.predict(Xi_test)\n",
    "ada_pred = ada_model.predict(Xi_test)\n",
    "xgb_pred = xgb_model.predict(Xi_test)\n",
    "nn_pred = nn_model.predict(Xi_test)\n",
    "\n",
    "# Evaluation: Mean Squared Error (MSE) on test set (imputed)\n",
    "svr_mse_i = mean_squared_error(yi_test, svr_pred)\n",
    "rf_mse_i = mean_squared_error(yi_test, rf_pred)\n",
    "ada_mse_i = mean_squared_error(yi_test, ada_pred)\n",
    "xgb_mse_i = mean_squared_error(yi_test, xgb_pred)\n",
    "nn_mse_i = mean_squared_error(yi_test, nn_pred)\n",
    "\n",
    "# Print results (imputed)\n",
    "print('RESULTS (IMPUTED)')\n",
    "print('-----------------')\n",
    "print(f\"Support Vector Regression MSE: {svr_mse_i:.2e}\")\n",
    "print(f\"Random Forest MSE: {rf_mse_i:.2e}\")\n",
    "print(f\"AdaBoost MSE: {ada_mse_i:.2e}\")\n",
    "print(f\"XGBoost MSE: {xgb_mse_i:.2e}\")\n",
    "print(f\"Neural Network MSE: {nn_mse_i:.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103a1dd3-9bb3-47bc-b0f5-47bd97fb57ba",
   "metadata": {},
   "source": [
    "RESULTS (DELETED)\n",
    "-----------------\n",
    "- Support Vector Regression MSE: 7.86e+09\n",
    "- Random Forest MSE: 8.32e+08\n",
    "- AdaBoost MSE: 1.35e+09\n",
    "- XGBoost MSE: 7.64e+08\n",
    "- Neural Network MSE: 5.88e+09\n",
    "\n",
    "RESULTS (IMPUTED)\n",
    "-----------------\n",
    "- Support Vector Regression MSE: 7.73e+09\n",
    "- Random Forest MSE: 8.59e+08\n",
    "- AdaBoost MSE: 1.34e+09\n",
    "- XGBoost MSE: 1.08e+09\n",
    "- Neural Network MSE: 7.69e+09\n",
    "\n",
    "## Initial thoughts:\n",
    "The square of the mean sale price (with no corrections for outliers) of the training dataset is 3.24e10 squared dollars (mean of $180k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "501db4d7-748c-4382-8778-4c5dd479d1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS (DELETED)\n",
      "-----------------\n",
      "Support Vector Regression MSE: 0.2425\n",
      "Random Forest MSE: 0.0257\n",
      "AdaBoost MSE: 0.0416\n",
      "XGBoost MSE: 0.0236\n",
      "Neural Network MSE: 0.1813\n",
      "RESULTS (IMPUTED)\n",
      "-----------------\n",
      "Support Vector Regression MSE: 0.2386\n",
      "Random Forest MSE: 0.0265\n",
      "AdaBoost MSE: 0.0415\n",
      "XGBoost MSE: 0.0334\n",
      "Neural Network MSE: 0.2373\n"
     ]
    }
   ],
   "source": [
    "# Compute percentage errors between MSE and average squared sale price\n",
    "m2 = 3.24e10 # avg sq sale price\n",
    "\n",
    "svrd = svr_mse_d/m2\n",
    "rfd = rf_mse_d/m2\n",
    "adad = ada_mse_d/m2\n",
    "xgbd = xgb_mse_d/m2\n",
    "nnd = nn_mse_d/m2\n",
    "svri = svr_mse_i/m2\n",
    "rfi = rf_mse_i/m2\n",
    "adai = ada_mse_i/m2\n",
    "xgbi = xgb_mse_i/m2\n",
    "nni = nn_mse_i/m2\n",
    "\n",
    "print('RESULTS (DELETED)')\n",
    "print('-----------------')\n",
    "print(f\"Support Vector Regression MSE: {svrd:.4f}\")\n",
    "print(f\"Random Forest MSE: {rfd:.4f}\")\n",
    "print(f\"AdaBoost MSE: {adad:.4f}\")\n",
    "print(f\"XGBoost MSE: {xgbd:.4f}\")\n",
    "print(f\"Neural Network MSE: {nnd:.4f}\")\n",
    "\n",
    "# Print results (imputed)\n",
    "print('RESULTS (IMPUTED)')\n",
    "print('-----------------')\n",
    "print(f\"Support Vector Regression MSE: {svri:.4f}\")\n",
    "print(f\"Random Forest MSE: {rfi:.4f}\")\n",
    "print(f\"AdaBoost MSE: {adai:.4f}\")\n",
    "print(f\"XGBoost MSE: {xgbi:.4f}\")\n",
    "print(f\"Neural Network MSE: {nni:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9f8cf3-d990-46d0-83f7-12d831c5cc84",
   "metadata": {},
   "source": [
    "RESULTS (DELETED)\n",
    "-----------------\n",
    "Support Vector Regression MSE: 0.2425\n",
    "Random Forest MSE: 0.0257\n",
    "AdaBoost MSE: 0.0416\n",
    "XGBoost MSE: 0.0236\n",
    "Neural Network MSE: 0.1813\n",
    "\n",
    "RESULTS (IMPUTED)\n",
    "-----------------\n",
    "Support Vector Regression MSE: 0.2386\n",
    "Random Forest MSE: 0.0265\n",
    "AdaBoost MSE: 0.0415\n",
    "XGBoost MSE: 0.0334\n",
    "Neural Network MSE: 0.2373\n",
    "\n",
    "## Further thoughts:\n",
    "The results are better nearly across the board for the models trained on datasets where features missing information were deleted vs imputed. The exception is the AdaBoost, although the results are nearly identical in that case.\n",
    "\n",
    "The overall best performing model was XGBoost on deleted data with an error of 2.36%, although Random Forest did comparably well for both datasets. Notably it outperforms XGBoost on the imputed dataset. This suggests to me that focusing on **XGBoost** and **RF models** is the way to go for further optimizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25399f46-330d-436e-aceb-14e8e1cb4264",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
